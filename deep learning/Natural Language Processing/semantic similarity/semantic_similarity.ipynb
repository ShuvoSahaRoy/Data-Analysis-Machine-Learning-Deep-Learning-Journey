{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrpHS4BOMhpv","outputId":"bd0edda2-c303-47a8-b870-bddf88939583"},"id":"LrpHS4BOMhpv","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","id":"f1ecde0c","metadata":{"id":"f1ecde0c"},"source":["### First step is to pre-process the CSV files\n","For that import CSV and os Module"]},{"cell_type":"code","execution_count":null,"id":"baa8c69d","metadata":{"id":"baa8c69d"},"outputs":[],"source":["import csv,os"]},{"cell_type":"markdown","id":"f74e6835","metadata":{"id":"f74e6835"},"source":["### User defined function data_process to process the CSV files.\n","If the CSV files are changed then the code needs to be changed"]},{"cell_type":"code","execution_count":null,"id":"288e24ee","metadata":{"id":"288e24ee"},"outputs":[],"source":["def data_process(file_path):\n","  file_name = os.path.basename(file_path)\n","  print(file_name)\n","  repaired_file_name = \"repaired_\" + file_name\n","  with open(file_path, 'r', encoding = 'utf-8') as infile, open(repaired_file_name,'w', encoding='utf-8') as outfile:\n","    for line in infile.readlines():\n","        error = 0\n","        try:\n","          # first read the csv file as a normal file to remove some special characters as string \",\"\n","            line = line.replace('\",\"', '')\n","            # line = line.replace('\",', '') # '\",'    I am not able to remove this 2 character as a string, because it breaks the format of the \n","            # csv file. But it can be done easily using string slicing . But my target is to keep it simple.\n","            outfile.write(line)\n","        except:\n","            error += 1\n","        \n","    if error==0:\n","      print('all lines are written successfully')\n","    else:\n","      print(f\"missed {error} lines\")\n","\n","  # after cleaning and storing data on a new csv file, now is the task is to extract the information from new csv file\n","  with open(repaired_file_name, 'r', encoding = 'utf-8-sig') as file:\n","      text1 = []                  # to store sentence for 1st sentence column \n","      text2 = []                  # to store sentence for 2nd sentence column \n","      label = []                  # to store the labels\n","      reader = csv.reader(file)\n","      count=1\n","      error = 0\n","      for row in reader:\n","          first_element = row[0]\n","          # check.append(first_element)\n","          try:\n","              sent2 = first_element.split('\\t')[6]\n","              sent1 = first_element.split('\\t')[5]\n","              target = first_element.split('\\t')[0]\n","              \n","              text2.append(sent2)\n","              text1.append(sent1)\n","              label.append(target)\n","          except:\n","              error+=1 \n","      if error==0:\n","        print('all lines are written successfully')\n","      else:\n","        print(f\"missed {error} lines\")\n","  return {'similarity': label,'text1': text1, 'text2': text2}"]},{"cell_type":"markdown","source":["## Set path of the dataset"],"metadata":{"id":"iW7j4ovO-6BP"},"id":"iW7j4ovO-6BP"},{"cell_type":"code","source":["# Just give the file path\n","trainig_data = data_process('/content/drive/MyDrive/delhi iit/stsbenchmark/sts-train.csv')\n","type(trainig_data)\n","test_data = data_process('/content/drive/MyDrive/delhi iit/stsbenchmark/sts-test.csv')\n","type(test_data)\n","val_data = data_process('/content/drive/MyDrive/delhi iit/stsbenchmark/sts-dev.csv')\n","type(val_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPPs6lvGOtsV","outputId":"3293c37f-8325-4671-fe51-a843d018dfeb"},"id":"vPPs6lvGOtsV","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-train.csv\n","all lines are written successfully\n","missed 210 lines\n","sts-test.csv\n","all lines are written successfully\n","missed 180 lines\n","sts-dev.csv\n","all lines are written successfully\n","missed 86 lines\n"]},{"output_type":"execute_result","data":{"text/plain":["dict"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["# Convert CSV to Pandas dataframe"],"metadata":{"id":"rF9CmNTO4Nrf"},"id":"rF9CmNTO4Nrf"},{"cell_type":"code","execution_count":null,"id":"2cd33018","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"2cd33018","outputId":"42e1ba0e-30ea-4bbe-e71b-ba431622e337"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      similarity                                          text1  \\\n","0  main-captions                         A plane is taking off.   \n","1  main-captions                A man is playing a large flute.   \n","2  main-captions  A man is spreading shreded cheese on a pizza.   \n","3  main-captions                   Three men are playing chess.   \n","4  main-captions                    A man is playing the cello.   \n","\n","                                               text2  \n","0                        An air plane is taking off.  \n","1                          A man is playing a flute.  \n","2  A man is spreading shredded cheese on an uncoo...  \n","3                         Two men are playing chess.  \n","4                 A man seated is playing the cello.  "],"text/html":["\n","  <div id=\"df-7e171d1e-d0f4-4cb6-b323-ea70dbbb8310\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>similarity</th>\n","      <th>text1</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>main-captions</td>\n","      <td>A plane is taking off.</td>\n","      <td>An air plane is taking off.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>main-captions</td>\n","      <td>A man is playing a large flute.</td>\n","      <td>A man is playing a flute.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>main-captions</td>\n","      <td>A man is spreading shreded cheese on a pizza.</td>\n","      <td>A man is spreading shredded cheese on an uncoo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>main-captions</td>\n","      <td>Three men are playing chess.</td>\n","      <td>Two men are playing chess.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>main-captions</td>\n","      <td>A man is playing the cello.</td>\n","      <td>A man seated is playing the cello.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e171d1e-d0f4-4cb6-b323-ea70dbbb8310')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7e171d1e-d0f4-4cb6-b323-ea70dbbb8310 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7e171d1e-d0f4-4cb6-b323-ea70dbbb8310');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":44}],"source":["import pandas as pd\n","# train data\n","train_df = pd.DataFrame(trainig_data)\n","train_df.head()"]},{"cell_type":"code","source":["# Test data\n","test_df = pd.DataFrame(test_data)\n","test_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"620Iqhi6oWDL","outputId":"bf6b49ee-fae1-4ac2-b19b-0dffae25353f"},"id":"620Iqhi6oWDL","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      similarity                                          text1  \\\n","0  main-captions                    A girl is styling her hair.   \n","1  main-captions       A group of men play soccer on the beach.   \n","2  main-captions  One woman is measuring another woman's ankle.   \n","3  main-captions                A man is cutting up a cucumber.   \n","4  main-captions                       A man is playing a harp.   \n","\n","                                              text2  \n","0                      A girl is brushing her hair.  \n","1  A group of boys are playing soccer on the beach.  \n","2           A woman measures another woman's ankle.  \n","3                      A man is slicing a cucumber.  \n","4                      A man is playing a keyboard.  "],"text/html":["\n","  <div id=\"df-2f42cc85-e978-49bd-8e40-180b18c4f42f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>similarity</th>\n","      <th>text1</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>main-captions</td>\n","      <td>A girl is styling her hair.</td>\n","      <td>A girl is brushing her hair.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>main-captions</td>\n","      <td>A group of men play soccer on the beach.</td>\n","      <td>A group of boys are playing soccer on the beach.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>main-captions</td>\n","      <td>One woman is measuring another woman's ankle.</td>\n","      <td>A woman measures another woman's ankle.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>main-captions</td>\n","      <td>A man is cutting up a cucumber.</td>\n","      <td>A man is slicing a cucumber.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>main-captions</td>\n","      <td>A man is playing a harp.</td>\n","      <td>A man is playing a keyboard.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f42cc85-e978-49bd-8e40-180b18c4f42f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f42cc85-e978-49bd-8e40-180b18c4f42f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f42cc85-e978-49bd-8e40-180b18c4f42f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# validation set\n","val_df = pd.DataFrame(val_data)\n","val_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"v6TeeDSXR7qM","outputId":"40090fb2-71db-44af-90a7-68683b56a8e3"},"id":"v6TeeDSXR7qM","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      similarity                                 text1  \\\n","0  main-captions     A man with a hard hat is dancing.   \n","1  main-captions      A young child is riding a horse.   \n","2  main-captions  A man is feeding a mouse to a snake.   \n","3  main-captions        A woman is playing the guitar.   \n","4  main-captions         A woman is playing the flute.   \n","\n","                                      text2  \n","0      A man wearing a hard hat is dancing.  \n","1                A child is riding a horse.  \n","2  The man is feeding a mouse to the snake.  \n","3                  A man is playing guitar.  \n","4                 A man is playing a flute.  "],"text/html":["\n","  <div id=\"df-69629e39-3576-4c2e-b174-3e05d4c1443e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>similarity</th>\n","      <th>text1</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>main-captions</td>\n","      <td>A man with a hard hat is dancing.</td>\n","      <td>A man wearing a hard hat is dancing.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>main-captions</td>\n","      <td>A young child is riding a horse.</td>\n","      <td>A child is riding a horse.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>main-captions</td>\n","      <td>A man is feeding a mouse to a snake.</td>\n","      <td>The man is feeding a mouse to the snake.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>main-captions</td>\n","      <td>A woman is playing the guitar.</td>\n","      <td>A man is playing guitar.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>main-captions</td>\n","      <td>A woman is playing the flute.</td>\n","      <td>A man is playing a flute.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69629e39-3576-4c2e-b174-3e05d4c1443e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-69629e39-3576-4c2e-b174-3e05d4c1443e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-69629e39-3576-4c2e-b174-3e05d4c1443e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# Shape of the data\n","print(f\"Total train samples : {train_df.shape[0]}\")\n","print(f\"Total validation samples: {val_df.shape[0]}\")\n","print(f\"Total test samples: {test_df.shape[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"biK99WuEqG7o","outputId":"98bb20c0-3a1b-433f-9305-00811ce3711f"},"id":"biK99WuEqG7o","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total train samples : 5005\n","Total validation samples: 1230\n","Total test samples: 1093\n"]}]},{"cell_type":"markdown","metadata":{"id":"BUxme_RA9LoP"},"source":["## Setup\n","\n","Note: install HuggingFace `transformers` via `pip install transformers`"],"id":"BUxme_RA9LoP"},{"cell_type":"code","execution_count":null,"id":"a344be08","metadata":{"id":"a344be08"},"outputs":[],"source":["# pip install transformers"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import transformers"],"metadata":{"id":"jE5o5JBDpDy1"},"id":"jE5o5JBDpDy1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['similarity'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_uToSXOpFbt","outputId":"627fcd70-09d4-4393-bd8d-7302c1abefff"},"id":"B_uToSXOpFbt","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['main-captions', 'main-forum', 'main-news'], dtype=object)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["max_length = 128  # Maximum length of input sentence to the model.\n","batch_size = 32\n","epochs = 2\n","\n","# Labels in our dataset.\n","labels = list(train_df['similarity'].unique())\n","labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDmgFRz7pPub","outputId":"d4dc5392-e9ae-46b2-a920-765e08c4c55f"},"id":"jDmgFRz7pPub","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['main-captions', 'main-forum', 'main-news']"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"rLDGraLA9LoY"},"source":["Let's look at one sample from the dataset:"],"id":"rLDGraLA9LoY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SRNDti79LoY","outputId":"56dfe1d9-ca2e-41be-d1f4-f31010a419a3","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence1: A man is playing a large flute.\n","Sentence2: A man is playing a flute.\n","Similarity: main-captions\n"]}],"source":["print(f\"Sentence1: {train_df.loc[1, 'text1']}\")\n","print(f\"Sentence2: {train_df.loc[1, 'text2']}\")\n","print(f\"Similarity: {train_df.loc[1, 'similarity']}\")"],"id":"4SRNDti79LoY"},{"cell_type":"markdown","metadata":{"id":"r_tz58_b9LoZ"},"source":["## Preprocessing"],"id":"r_tz58_b9LoZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHLuJM-Q9Loa","outputId":"cfc15736-3839-448a-cc76-d2b7ae9607bc","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of missing values\n","similarity    0\n","text1         0\n","text2         0\n","dtype: int64\n"]}],"source":["# We have some NaN entries in our train data, we will simply drop them.\n","print(\"Number of missing values\")\n","print(train_df.isnull().sum())\n","train_df.dropna(axis=0, inplace=True)"],"id":"aHLuJM-Q9Loa"},{"cell_type":"markdown","metadata":{"id":"ku-ZxEbj9Loa"},"source":["Distribution of our training targets."],"id":"ku-ZxEbj9Loa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1C4p94fq9Loa","outputId":"9f76cd15-f9fa-4c4c-b1fa-c9359b9a1a57","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Target Distribution\n","main-news        2577\n","main-captions    1994\n","main-forum        434\n","Name: similarity, dtype: int64\n"]}],"source":["print(\"Train Target Distribution\")\n","print(train_df.similarity.value_counts())"],"id":"1C4p94fq9Loa"},{"cell_type":"markdown","metadata":{"id":"gys8g34S9Lob"},"source":["Distribution of our validation targets."],"id":"gys8g34S9Lob"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KC-Obdhx9Lob","outputId":"d8b5af92-ed98-44b8-adf2-52089a55d9eb","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Target Distribution\n","main-captions    623\n","main-forums      331\n","main-news        276\n","Name: similarity, dtype: int64\n"]}],"source":["print(\"Validation Target Distribution\")\n","print(val_df.similarity.value_counts())"],"id":"KC-Obdhx9Lob"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMx-WEcB9Loc"},"outputs":[],"source":["train_df = (\n","    train_df[train_df.similarity != \"-\"]\n","    .sample(frac=1.0, random_state=42)\n","    .reset_index(drop=True)\n",")\n","valid_df = (\n","    val_df[val_df.similarity != \"-\"]\n","    .sample(frac=1.0, random_state=42)\n","    .reset_index(drop=True)\n",")"],"id":"iMx-WEcB9Loc"},{"cell_type":"markdown","metadata":{"id":"9u4Wh9R99Loc"},"source":["One-hot encode training, validation, and test labels."],"id":"9u4Wh9R99Loc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOmP_-qN9Loc"},"outputs":[],"source":["train_df[\"label\"] = train_df[\"similarity\"].apply(\n","    lambda x: 0 if x == \"main-captions\" else 1 if x == \"main-forum\" else 2\n",")\n","y_train = tf.keras.utils.to_categorical(train_df.label, num_classes=3)\n","\n","valid_df[\"label\"] = valid_df[\"similarity\"].apply(\n","    lambda x: 0 if x == \"main-captions\" else 1 if x == \"main-forum\" else 2\n",")\n","y_val = tf.keras.utils.to_categorical(valid_df.label, num_classes=3)\n","\n","test_df[\"label\"] = test_df[\"similarity\"].apply(\n","    lambda x: 0 if x == \"main-captions\" else 1 if x == \"main-forum\" else 2\n",")\n","y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=3)"],"id":"sOmP_-qN9Loc"},{"cell_type":"code","source":["train_df.label.unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BWWYsC3sBEU","outputId":"47c8a76f-f829-4732-e404-4b98473254e7"},"id":"6BWWYsC3sBEU","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 0, 1])"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"eOz1p2gW9Lod"},"source":["## Keras Custom Data Generator\n","Ref: Keras.io"],"id":"eOz1p2gW9Lod"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxsECOf69Lod"},"outputs":[],"source":["\n","class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n","    \"\"\"Generates batches of data.\n","\n","    Args:\n","        sentence_pairs: Array of premise and hypothesis input sentences.\n","        labels: Array of labels.\n","        batch_size: Integer batch size.\n","        shuffle: boolean, whether to shuffle the data.\n","        include_targets: boolean, whether to incude the labels.\n","\n","    Returns:\n","        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n","        (or just `[input_ids, attention_mask, `token_type_ids]`\n","         if `include_targets=False`)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        sentence_pairs,\n","        labels,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        include_targets=True,\n","    ):\n","        self.sentence_pairs = sentence_pairs\n","        self.labels = labels\n","        self.shuffle = shuffle\n","        self.batch_size = batch_size\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        # We will use base-base-uncased pretrained model.\n","        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n","            \"bert-base-uncased\", do_lower_case=True\n","        )\n","        self.indexes = np.arange(len(self.sentence_pairs))\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.sentence_pairs) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        sentence_pairs = self.sentence_pairs[indexes]\n","\n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            sentence_pairs.tolist(),\n","            add_special_tokens=True,\n","            max_length=max_length,\n","            return_attention_mask=True,\n","            return_token_type_ids=True,\n","            pad_to_max_length=True,\n","            return_tensors=\"tf\",\n","        )\n","\n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n","\n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            labels = np.array(self.labels[indexes], dtype=\"int32\")\n","            return [input_ids, attention_masks, token_type_ids], labels\n","        else:\n","            return [input_ids, attention_masks, token_type_ids]\n","\n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)\n"],"id":"nxsECOf69Lod"},{"cell_type":"markdown","metadata":{"id":"suVG2cfx9Lod"},"source":["## Build the model.\n","Ref: Keras.io"],"id":"suVG2cfx9Lod"},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAaeJ2Kb9Loe","outputId":"dcbae11d-ab81-4af8-b96a-59832415caba","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7ffab14ab1d0>\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 128)]        0           []                               \n","                                                                                                  \n"," attention_masks (InputLayer)   [(None, 128)]        0           []                               \n","                                                                                                  \n"," token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n","                                                                                                  \n"," bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n","                                tentions(last_hidde               'token_type_ids[0][0]']         \n","                                n_state=(None, 128,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, 128, 128)    426496      ['bert[0][0]']                   \n"," )                                                                                                \n","                                                                                                  \n"," global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional_1[0][0]']        \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_max_pooling1d_1 (Global  (None, 128)         0           ['bidirectional_1[0][0]']        \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256)          0           ['global_average_pooling1d_1[0][0\n","                                                                 ]',                              \n","                                                                  'global_max_pooling1d_1[0][0]'] \n","                                                                                                  \n"," dropout_75 (Dropout)           (None, 256)          0           ['concatenate_1[0][0]']          \n","                                                                                                  \n"," dense_1 (Dense)                (None, 3)            771         ['dropout_75[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,909,507\n","Trainable params: 427,267\n","Non-trainable params: 109,482,240\n","__________________________________________________________________________________________________\n"]}],"source":["# Create the model under a distribution strategy scope.\n","strategy = tf.distribute.MirroredStrategy()\n","\n","with strategy.scope():\n","    # Encoded token ids from BERT tokenizer.\n","    input_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n","    )\n","    # Attention masks indicates to the model which tokens should be attended to.\n","    attention_masks = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n","    )\n","    # Token type ids are binary masks identifying different sequences in the model.\n","    token_type_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n","    )\n","    # Loading pretrained BERT model.\n","    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n","    # Freeze the BERT model to reuse the pretrained features without modifying them.\n","    bert_model.trainable = False\n","\n","    bert_output = bert_model.bert(\n","        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n","    )\n","    sequence_output = bert_output.last_hidden_state\n","    pooled_output = bert_output.pooler_output\n","    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n","    bi_lstm = tf.keras.layers.Bidirectional(\n","        tf.keras.layers.LSTM(64, return_sequences=True)\n","    )(sequence_output)\n","    # Applying hybrid pooling approach to bi_lstm sequence output.\n","    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n","    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n","    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n","    dropout = tf.keras.layers.Dropout(0.3)(concat)\n","    output = tf.keras.layers.Dense(3, activation=\"softmax\")(dropout)\n","    model = tf.keras.models.Model(\n","        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n","    )\n","\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"acc\"],\n","    )\n","\n","\n","print(f\"Strategy: {strategy}\")\n","model.summary()"],"id":"oAaeJ2Kb9Loe"},{"cell_type":"markdown","metadata":{"id":"EXLRRU9-9Loe"},"source":["Create train and validation data generators"],"id":"EXLRRU9-9Loe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOo9kGE29Loe"},"outputs":[],"source":["train_data = BertSemanticDataGenerator(\n","    train_df[[\"text1\", \"text2\"]].values.astype(\"str\"),\n","    y_train,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","valid_data = BertSemanticDataGenerator(\n","    valid_df[[\"text1\", \"text2\"]].values.astype(\"str\"),\n","    y_val,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")"],"id":"SOo9kGE29Loe"},{"cell_type":"markdown","metadata":{"id":"VzxdLiF19Lof"},"source":["## Train the Model\n","\n","Training is done only for the top layers to perform \"feature extraction\",\n","which will allow the model to use the representations of the pretrained model."],"id":"VzxdLiF19Lof"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oARoqPU9Lof","outputId":"3c888b90-9a75-4d6c-b7af-2d3a2b4b9158","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","156/156 [==============================] - ETA: 0s - loss: 0.0942 - acc: 0.9659 "]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r156/156 [==============================] - 2819s 18s/step - loss: 0.0942 - acc: 0.9659 - val_loss: 0.3828 - val_acc: 0.8215\n","Epoch 2/2\n","156/156 [==============================] - 2627s 17s/step - loss: 0.0350 - acc: 0.9894 - val_loss: 0.7724 - val_acc: 0.7541\n"]}],"source":["history = model.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"],"id":"0oARoqPU9Lof"},{"cell_type":"markdown","metadata":{"id":"v7dyYGXK9Lof"},"source":["## Fine-tuning\n","\n","This step must only be performed after the feature extraction model has\n","been trained to convergence on the new data.\n","\n","This is an optional last step where `bert_model` is unfreezed and retrained\n","with a very low learning rate. This can deliver meaningful improvement by\n","incrementally adapting the pretrained features to the new data."],"id":"v7dyYGXK9Lof"},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0QH82Dy9Log","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ae696b2-a26c-4a0c-f71b-28f73cd61b0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 128)]        0           []                               \n","                                                                                                  \n"," attention_masks (InputLayer)   [(None, 128)]        0           []                               \n","                                                                                                  \n"," token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n","                                                                                                  \n"," bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n","                                tentions(last_hidde               'token_type_ids[0][0]']         \n","                                n_state=(None, 128,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, 128, 128)    426496      ['bert[0][0]']                   \n"," )                                                                                                \n","                                                                                                  \n"," global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional_1[0][0]']        \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_max_pooling1d_1 (Global  (None, 128)         0           ['bidirectional_1[0][0]']        \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256)          0           ['global_average_pooling1d_1[0][0\n","                                                                 ]',                              \n","                                                                  'global_max_pooling1d_1[0][0]'] \n","                                                                                                  \n"," dropout_75 (Dropout)           (None, 256)          0           ['concatenate_1[0][0]']          \n","                                                                                                  \n"," dense_1 (Dense)                (None, 3)            771         ['dropout_75[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,909,507\n","Trainable params: 109,909,507\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# Unfreeze the bert_model.\n","bert_model.trainable = True\n","# Recompile the model to make the change effective.\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(1e-5),\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","model.summary()"],"id":"i0QH82Dy9Log"},{"cell_type":"markdown","metadata":{"id":"wlPsCJ3_9Log"},"source":["# Train the entire model end-to-end."],"id":"wlPsCJ3_9Log"},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZD6Qq7Y9Log","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c17848d-3930-4c08-811d-9f37c6b0cc34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["156/156 [==============================] - 6849s 44s/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.4635 - val_accuracy: 0.8355\n","Epoch 2/2\n","156/156 [==============================] - 7004s 45s/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.9686 - val_accuracy: 0.7549\n"]}],"source":["history = model.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"],"id":"PZD6Qq7Y9Log"},{"cell_type":"markdown","metadata":{"id":"kOk2i3aL9Log"},"source":["## Evaluate model on the test set"],"id":"kOk2i3aL9Log"},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjm5Lpdt9Loh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4ad5399-4715-4d56-8106-9418198277c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["34/34 [==============================] - 439s 13s/step - loss: 1.2315 - accuracy: 0.8180\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.2314528226852417, 0.8180146813392639]"]},"metadata":{},"execution_count":72}],"source":["test_data = BertSemanticDataGenerator(\n","    test_df[[\"text1\", \"text2\"]].values.astype(\"str\"),\n","    y_test,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")\n","model.evaluate(test_data, verbose=1)"],"id":"xjm5Lpdt9Loh"},{"cell_type":"markdown","source":["# Save model"],"metadata":{"id":"5-fLzLOGGOJi"},"id":"5-fLzLOGGOJi"},{"cell_type":"code","source":["model.save(\"with fine tunnig.h5\")"],"metadata":{"id":"7kyBP0viGNDL"},"id":"7kyBP0viGNDL","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pfESgBS9Loh"},"source":["## Inference on custom sentences"],"id":"1pfESgBS9Loh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilZUbjnQ9Loh"},"outputs":[],"source":["\n","def check_similarity(sentence1, sentence2):\n","    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n","    test_data = BertSemanticDataGenerator(\n","        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n","    )\n","\n","    proba = model.predict(test_data[0])[0]\n","    idx = np.argmax(proba)\n","    proba = f\"{proba[idx]: .2f}%\"\n","    pred = labels[idx]\n","    return pred, proba\n"],"id":"ilZUbjnQ9Loh"},{"cell_type":"markdown","metadata":{"id":"45KEtOnM9Loh"},"source":["Check results on some example sentence pairs."],"id":"45KEtOnM9Loh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"xA-886gt9Loi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb94783e-2b56-406a-ba5f-7f16ce09ef39"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 7s 7s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('main-captions', ' 1.00%')"]},"metadata":{},"execution_count":75}],"source":["sentence1 = \"Two women are observing something together.\"\n","sentence2 = \"Two women are standing with their eyes closed.\"\n","check_similarity(sentence1, sentence2)"],"id":"xA-886gt9Loi"},{"cell_type":"markdown","metadata":{"id":"5qENk7589Loi"},"source":["Check results on some example sentence pairs."],"id":"5qENk7589Loi"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTyXagCD9Loi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9190a177-6fb1-4e91-8e7e-fd349f38b3a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 577ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('main-captions', ' 1.00%')"]},"metadata":{},"execution_count":76}],"source":["sentence1 = \"A smiling costumed woman is holding an umbrella\"\n","sentence2 = \"A happy woman in a fairy costume holds an umbrella\"\n","check_similarity(sentence1, sentence2)"],"id":"RTyXagCD9Loi"},{"cell_type":"markdown","metadata":{"id":"XFAbLnFP9Loi"},"source":["Check results on some example sentence pairs"],"id":"XFAbLnFP9Loi"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjoy1SIN9Loi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"99996bea-3a14-43e5-cf86-b0f60c9b351d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 575ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('main-captions', ' 1.00%')"]},"metadata":{},"execution_count":77}],"source":["sentence1 = \"A soccer game with multiple males playing\"\n","sentence2 = \"Some men are playing a sport\"\n","check_similarity(sentence1, sentence2)"],"id":"gjoy1SIN9Loi"},{"cell_type":"code","source":[],"metadata":{"id":"tSzKYsY1HaSu"},"id":"tSzKYsY1HaSu","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"forML","language":"python","name":"forml"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}