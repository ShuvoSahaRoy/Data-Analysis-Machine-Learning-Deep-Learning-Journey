{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7020b66",
   "metadata": {},
   "source": [
    "### Load all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef950d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import csv,re\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ab66a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecde0c",
   "metadata": {},
   "source": [
    "### To ignore character dring tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baa8c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af1896",
   "metadata": {},
   "source": [
    "### If csv pre processing needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d73327e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('stsbenchmark/sts-train.csv', 'r', encoding = 'utf-8') as infile, open('repaired.csv','w', encoding='utf-8') as outfile:\n",
    "#     for line in infile.readlines():\n",
    "#         error = 0\n",
    "#         try:\n",
    "#             line = line.replace('\",\"', '')\n",
    "#             # line = line.replace('\",', '')\n",
    "#             outfile.write(line)\n",
    "#         except:\n",
    "#             error += 1\n",
    "        \n",
    "#     print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e6835",
   "metadata": {},
   "source": [
    "### Now csv to dataframe and data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "288e24ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    }
   ],
   "source": [
    "with open('repaired.csv', 'r', encoding = 'utf-8-sig') as file:\n",
    "    text1 = []\n",
    "    text2 = []\n",
    "    # check = []\n",
    "    reader = csv.reader(file)\n",
    "    count=1\n",
    "    error = 0\n",
    "    for row in reader:\n",
    "        first_element = row[0]\n",
    "        # check.append(first_element)\n",
    "        \n",
    "        try:\n",
    "            sent2 = first_element.split('\\t')[6]\n",
    "            sent1 = first_element.split('\\t')[5]\n",
    "            \n",
    "            sent1 = re.sub(r'\\[[0-9]*\\]',' ',sent1)\n",
    "            sent1 = re.sub(r'\\s+',' ',sent1)\n",
    "            sent1 = sent1.lower()\n",
    "            sent1 = tokenizer.tokenize(sent1)\n",
    "            \n",
    "            for i in range(len(sent1)):\n",
    "                sent1 = [word for word in sent1 if word not in stopwords.words('english')]\n",
    "            \n",
    "            sent2 = re.sub(r'\\[[0-9]*\\]',' ',sent2)\n",
    "            sent2 = re.sub(r'\\s+',' ',sent2)\n",
    "            sent2 = sent2.lower()\n",
    "            sent2 = tokenizer.tokenize(sent2)\n",
    "            \n",
    "            for i in range(len(sent2)):\n",
    "                sent2 = [word for word in sent2 if word not in stopwords.words('english')]\n",
    "            \n",
    "            text2.append(sent2)\n",
    "            text1.append(sent1)\n",
    "        except:\n",
    "            error+=1 \n",
    "        \n",
    "    print(error) ### error represent, how much data it skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cd33018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5005, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'text1': text1, 'text2': text2})\n",
    "\n",
    "copydata=data.copy()\n",
    "copydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6f50d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plane, taking]</td>\n",
       "      <td>[air, plane, taking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[man, playing, large, flute]</td>\n",
       "      <td>[man, playing, flute]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[man, spreading, shreded, cheese, pizza]</td>\n",
       "      <td>[man, spreading, shredded, cheese, uncooked, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[three, men, playing, chess]</td>\n",
       "      <td>[two, men, playing, chess]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[man, playing, cello]</td>\n",
       "      <td>[man, seated, playing, cello]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text1  \\\n",
       "0                           [plane, taking]   \n",
       "1              [man, playing, large, flute]   \n",
       "2  [man, spreading, shreded, cheese, pizza]   \n",
       "3              [three, men, playing, chess]   \n",
       "4                     [man, playing, cello]   \n",
       "\n",
       "                                               text2  \n",
       "0                               [air, plane, taking]  \n",
       "1                              [man, playing, flute]  \n",
       "2  [man, spreading, shredded, cheese, uncooked, p...  \n",
       "3                         [two, men, playing, chess]  \n",
       "4                      [man, seated, playing, cello]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copydata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6a69c",
   "metadata": {},
   "source": [
    "### Count vectorizer similarity and Tf IDF similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa13b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vcr():\n",
    "  for i in range(len(copydata)):\n",
    "    doc1=copydata['text1'][i]\n",
    "    doc2=copydata['text2'][i]\n",
    "    docs=(doc1,doc2)\n",
    "    matrix = CountVectorizer().fit_transform(docs)\n",
    "    cosine_sim = cosine_similarity(matrix[0], matrix[1])\n",
    "    similarity.append(cosine_sim)\n",
    "  return similarity\n",
    "\n",
    "def similarity_fn():\n",
    "  for i in range(len(copydata)):\n",
    "    doc1=copydata['text1'][i]\n",
    "    doc2=copydata['text2'][i]\n",
    "    docs=(doc1,doc2)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(docs)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "    similarity.append(cosine_sim)\n",
    "  return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0378fcb9",
   "metadata": {},
   "source": [
    "### Count Vecotrizer and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "815d93a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plane taking</td>\n",
       "      <td>air plane taking</td>\n",
       "      <td>[[0.816496580927726]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man playing large flute</td>\n",
       "      <td>man playing flute</td>\n",
       "      <td>[[0.8660254037844388]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man spreading shreded cheese pizza</td>\n",
       "      <td>man spreading shredded cheese uncooked pizza</td>\n",
       "      <td>[[0.7302967433402215]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three men playing chess</td>\n",
       "      <td>two men playing chess</td>\n",
       "      <td>[[0.75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man playing cello</td>\n",
       "      <td>man seated playing cello</td>\n",
       "      <td>[[0.8660254037844388]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text1  \\\n",
       "0                        plane taking   \n",
       "1             man playing large flute   \n",
       "2  man spreading shreded cheese pizza   \n",
       "3             three men playing chess   \n",
       "4                   man playing cello   \n",
       "\n",
       "                                          text2              Similarity  \n",
       "0                              air plane taking   [[0.816496580927726]]  \n",
       "1                             man playing flute  [[0.8660254037844388]]  \n",
       "2  man spreading shredded cheese uncooked pizza  [[0.7302967433402215]]  \n",
       "3                         two men playing chess                [[0.75]]  \n",
       "4                      man seated playing cello  [[0.8660254037844388]]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_converter = CountVectorizer()\n",
    "copydata.pipe(detoken).pipe(remove_space)\n",
    "similarity=[]\n",
    "similarity=count_vcr()\n",
    "data_cvr=copydata.copy()\n",
    "data_cvr['Similarity']=similarity\n",
    "data_cvr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85794e7c",
   "metadata": {},
   "source": [
    "### Tf-Idf Vecotrizer and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20906453",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "similarity=[]\n",
    "similarity=similarity_fn()\n",
    "data_tf=copydata.copy()\n",
    "data_tf['Similarity']=similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a0e4e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>Count-Vec Similarity</th>\n",
       "      <th>Tf-idf Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plane taking</td>\n",
       "      <td>air plane taking</td>\n",
       "      <td>[[0.816496580927726]]</td>\n",
       "      <td>[[0.7092972666062739]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man playing large flute</td>\n",
       "      <td>man playing flute</td>\n",
       "      <td>[[0.8660254037844388]]</td>\n",
       "      <td>[[0.7765145304745156]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man spreading shreded cheese pizza</td>\n",
       "      <td>man spreading shredded cheese uncooked pizza</td>\n",
       "      <td>[[0.7302967433402215]]</td>\n",
       "      <td>[[0.5803329846765686]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three men playing chess</td>\n",
       "      <td>two men playing chess</td>\n",
       "      <td>[[0.75]]</td>\n",
       "      <td>[[0.6029748160380572]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man playing cello</td>\n",
       "      <td>man seated playing cello</td>\n",
       "      <td>[[0.8660254037844388]]</td>\n",
       "      <td>[[0.7765145304745156]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>severe gales storm clodagh hits britain</td>\n",
       "      <td>merkel pledges nato solidarity latvia</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>dozens egyptians hostages taken libyan terrori...</td>\n",
       "      <td>egyptian boat crash death toll rises bodies fo...</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>president heading bahrain</td>\n",
       "      <td>president xi china continue help fight ebola</td>\n",
       "      <td>[[0.2182178902359924]]</td>\n",
       "      <td>[[0.12536693798731732]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>china india vow bilateral ties</td>\n",
       "      <td>china scrambles reassure jittery stock traders</td>\n",
       "      <td>[[0.18257418583505539]]</td>\n",
       "      <td>[[0.10163066979112656]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>putin spokesman doping charges appear unfounded</td>\n",
       "      <td>latest severe weather 1 dead texas tornado</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5005 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0                                          plane taking   \n",
       "1                               man playing large flute   \n",
       "2                    man spreading shreded cheese pizza   \n",
       "3                               three men playing chess   \n",
       "4                                     man playing cello   \n",
       "...                                                 ...   \n",
       "5000            severe gales storm clodagh hits britain   \n",
       "5001  dozens egyptians hostages taken libyan terrori...   \n",
       "5002                          president heading bahrain   \n",
       "5003                     china india vow bilateral ties   \n",
       "5004    putin spokesman doping charges appear unfounded   \n",
       "\n",
       "                                                  text2  \\\n",
       "0                                      air plane taking   \n",
       "1                                     man playing flute   \n",
       "2          man spreading shredded cheese uncooked pizza   \n",
       "3                                 two men playing chess   \n",
       "4                              man seated playing cello   \n",
       "...                                                 ...   \n",
       "5000              merkel pledges nato solidarity latvia   \n",
       "5001  egyptian boat crash death toll rises bodies fo...   \n",
       "5002       president xi china continue help fight ebola   \n",
       "5003     china scrambles reassure jittery stock traders   \n",
       "5004         latest severe weather 1 dead texas tornado   \n",
       "\n",
       "         Count-Vec Similarity        Tf-idf Similarity  \n",
       "0       [[0.816496580927726]]   [[0.7092972666062739]]  \n",
       "1      [[0.8660254037844388]]   [[0.7765145304745156]]  \n",
       "2      [[0.7302967433402215]]   [[0.5803329846765686]]  \n",
       "3                    [[0.75]]   [[0.6029748160380572]]  \n",
       "4      [[0.8660254037844388]]   [[0.7765145304745156]]  \n",
       "...                       ...                      ...  \n",
       "5000                  [[0.0]]                  [[0.0]]  \n",
       "5001                  [[0.0]]                  [[0.0]]  \n",
       "5002   [[0.2182178902359924]]  [[0.12536693798731732]]  \n",
       "5003  [[0.18257418583505539]]  [[0.10163066979112656]]  \n",
       "5004                  [[0.0]]                  [[0.0]]  \n",
       "\n",
       "[5005 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=data_cvr.copy()\n",
    "all_data['Count-Vec Similarity']=all_data['Similarity']\n",
    "all_data=all_data.drop('Similarity',axis=1)\n",
    "all_data['Tf-idf Similarity']=data_tf['Similarity']\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344be08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forML",
   "language": "python",
   "name": "forml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
